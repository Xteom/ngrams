{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# hola\n",
    "* adios\n",
    "    \n",
    "    * bueno\n",
    "        * ahhh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Para crear el ambiente corremos en la terminal:\n",
    "``` bash\n",
    "conda create --name Ngram python=3.8.19\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "%pip install numpy\n",
    "%pip install scipy\n",
    "%pip install cython\n",
    "%pip install gensim\n",
    "%pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##year_1 and year_2 comprise the time period of ngrams to read##\n",
    "year_1=2017\n",
    "year_2=2018\n",
    "\n",
    "import numpy\n",
    "import scipy\n",
    "import cython\n",
    "import gensim\n",
    "from gensim import models, similarities\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import sys  \n",
    "import itertools\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 18:34:01,835 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=300, alpha=0.025>', 'datetime': '2024-04-16T18:34:01.835127', 'gensim': '4.3.2', 'python': '3.8.19 | packaged by conda-forge | (default, Mar 20 2024, 12:38:07) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2024-04-16 18:34:01,835 : INFO : collecting all words and their counts\n",
      "2024-04-16 18:34:01,839 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-04-16 18:34:01,856 : INFO : PROGRESS: at sentence #10000, processed 50000 words, keeping 524 word types\n",
      "2024-04-16 18:34:01,873 : INFO : PROGRESS: at sentence #20000, processed 100000 words, keeping 873 word types\n",
      "2024-04-16 18:34:01,891 : INFO : PROGRESS: at sentence #30000, processed 150000 words, keeping 1087 word types\n",
      "2024-04-16 18:34:01,906 : INFO : PROGRESS: at sentence #40000, processed 200000 words, keeping 1330 word types\n",
      "2024-04-16 18:34:01,918 : INFO : PROGRESS: at sentence #50000, processed 250000 words, keeping 1492 word types\n",
      "2024-04-16 18:34:01,933 : INFO : PROGRESS: at sentence #60000, processed 300000 words, keeping 1664 word types\n",
      "2024-04-16 18:34:01,942 : INFO : PROGRESS: at sentence #70000, processed 350000 words, keeping 1830 word types\n",
      "2024-04-16 18:34:01,966 : INFO : PROGRESS: at sentence #80000, processed 400000 words, keeping 1972 word types\n",
      "2024-04-16 18:34:01,974 : INFO : PROGRESS: at sentence #90000, processed 450000 words, keeping 2073 word types\n",
      "2024-04-16 18:34:01,996 : INFO : PROGRESS: at sentence #100000, processed 500000 words, keeping 2223 word types\n",
      "2024-04-16 18:34:02,008 : INFO : PROGRESS: at sentence #110000, processed 550000 words, keeping 2358 word types\n",
      "2024-04-16 18:34:02,018 : INFO : PROGRESS: at sentence #120000, processed 600000 words, keeping 2478 word types\n",
      "2024-04-16 18:34:02,032 : INFO : PROGRESS: at sentence #130000, processed 650000 words, keeping 2560 word types\n",
      "2024-04-16 18:34:02,052 : INFO : PROGRESS: at sentence #140000, processed 700000 words, keeping 2685 word types\n",
      "2024-04-16 18:34:02,063 : INFO : PROGRESS: at sentence #150000, processed 750000 words, keeping 2756 word types\n",
      "2024-04-16 18:34:02,074 : INFO : PROGRESS: at sentence #160000, processed 800000 words, keeping 2856 word types\n",
      "2024-04-16 18:34:02,085 : INFO : PROGRESS: at sentence #170000, processed 850000 words, keeping 2966 word types\n",
      "2024-04-16 18:34:02,107 : INFO : PROGRESS: at sentence #180000, processed 900000 words, keeping 3081 word types\n",
      "2024-04-16 18:34:02,119 : INFO : PROGRESS: at sentence #190000, processed 950000 words, keeping 3169 word types\n",
      "2024-04-16 18:34:02,130 : INFO : PROGRESS: at sentence #200000, processed 1000000 words, keeping 3236 word types\n",
      "2024-04-16 18:34:02,141 : INFO : PROGRESS: at sentence #210000, processed 1050000 words, keeping 3348 word types\n",
      "2024-04-16 18:34:02,162 : INFO : PROGRESS: at sentence #220000, processed 1100000 words, keeping 3436 word types\n",
      "2024-04-16 18:34:02,174 : INFO : PROGRESS: at sentence #230000, processed 1150000 words, keeping 3532 word types\n",
      "2024-04-16 18:34:02,185 : INFO : PROGRESS: at sentence #240000, processed 1200000 words, keeping 3619 word types\n",
      "2024-04-16 18:34:02,206 : INFO : PROGRESS: at sentence #250000, processed 1250000 words, keeping 3678 word types\n",
      "2024-04-16 18:34:02,219 : INFO : PROGRESS: at sentence #260000, processed 1300000 words, keeping 3751 word types\n",
      "2024-04-16 18:34:02,230 : INFO : PROGRESS: at sentence #270000, processed 1350000 words, keeping 3828 word types\n",
      "2024-04-16 18:34:02,241 : INFO : PROGRESS: at sentence #280000, processed 1400000 words, keeping 3909 word types\n",
      "2024-04-16 18:34:02,261 : INFO : PROGRESS: at sentence #290000, processed 1450000 words, keeping 3995 word types\n",
      "2024-04-16 18:34:02,274 : INFO : PROGRESS: at sentence #300000, processed 1500000 words, keeping 4081 word types\n",
      "2024-04-16 18:34:02,285 : INFO : PROGRESS: at sentence #310000, processed 1550000 words, keeping 4163 word types\n",
      "2024-04-16 18:34:02,305 : INFO : PROGRESS: at sentence #320000, processed 1600000 words, keeping 4244 word types\n",
      "2024-04-16 18:34:02,320 : INFO : PROGRESS: at sentence #330000, processed 1650000 words, keeping 4298 word types\n",
      "2024-04-16 18:34:02,335 : INFO : PROGRESS: at sentence #340000, processed 1700000 words, keeping 4370 word types\n",
      "2024-04-16 18:34:02,350 : INFO : PROGRESS: at sentence #350000, processed 1750000 words, keeping 4431 word types\n",
      "2024-04-16 18:34:02,364 : INFO : PROGRESS: at sentence #360000, processed 1800000 words, keeping 4484 word types\n",
      "2024-04-16 18:34:02,377 : INFO : PROGRESS: at sentence #370000, processed 1850000 words, keeping 4528 word types\n",
      "2024-04-16 18:34:02,385 : INFO : PROGRESS: at sentence #380000, processed 1900000 words, keeping 4604 word types\n",
      "2024-04-16 18:34:02,407 : INFO : PROGRESS: at sentence #390000, processed 1950000 words, keeping 4668 word types\n",
      "2024-04-16 18:34:02,422 : INFO : PROGRESS: at sentence #400000, processed 2000000 words, keeping 4739 word types\n",
      "2024-04-16 18:34:02,438 : INFO : PROGRESS: at sentence #410000, processed 2050000 words, keeping 4805 word types\n",
      "2024-04-16 18:34:02,451 : INFO : PROGRESS: at sentence #420000, processed 2100000 words, keeping 4850 word types\n",
      "2024-04-16 18:34:02,466 : INFO : PROGRESS: at sentence #430000, processed 2150000 words, keeping 4918 word types\n",
      "2024-04-16 18:34:02,477 : INFO : PROGRESS: at sentence #440000, processed 2200000 words, keeping 4969 word types\n",
      "2024-04-16 18:34:02,496 : INFO : PROGRESS: at sentence #450000, processed 2250000 words, keeping 5024 word types\n",
      "2024-04-16 18:34:02,509 : INFO : PROGRESS: at sentence #460000, processed 2300000 words, keeping 5073 word types\n",
      "2024-04-16 18:34:02,527 : INFO : PROGRESS: at sentence #470000, processed 2350000 words, keeping 5138 word types\n",
      "2024-04-16 18:34:02,539 : INFO : PROGRESS: at sentence #480000, processed 2400000 words, keeping 5155 word types\n",
      "2024-04-16 18:34:02,554 : INFO : PROGRESS: at sentence #490000, processed 2450000 words, keeping 5217 word types\n",
      "2024-04-16 18:34:02,574 : INFO : PROGRESS: at sentence #500000, processed 2500000 words, keeping 5264 word types\n",
      "2024-04-16 18:34:02,588 : INFO : PROGRESS: at sentence #510000, processed 2550000 words, keeping 5297 word types\n",
      "2024-04-16 18:34:02,599 : INFO : PROGRESS: at sentence #520000, processed 2600000 words, keeping 5336 word types\n",
      "2024-04-16 18:34:02,610 : INFO : PROGRESS: at sentence #530000, processed 2650000 words, keeping 5370 word types\n",
      "2024-04-16 18:34:02,630 : INFO : PROGRESS: at sentence #540000, processed 2700000 words, keeping 5405 word types\n",
      "2024-04-16 18:34:02,643 : INFO : PROGRESS: at sentence #550000, processed 2750000 words, keeping 5441 word types\n",
      "2024-04-16 18:34:02,654 : INFO : PROGRESS: at sentence #560000, processed 2800000 words, keeping 5476 word types\n",
      "2024-04-16 18:34:02,674 : INFO : PROGRESS: at sentence #570000, processed 2850000 words, keeping 5516 word types\n",
      "2024-04-16 18:34:02,688 : INFO : PROGRESS: at sentence #580000, processed 2900000 words, keeping 5559 word types\n",
      "2024-04-16 18:34:02,698 : INFO : PROGRESS: at sentence #590000, processed 2950000 words, keeping 5592 word types\n",
      "2024-04-16 18:34:02,718 : INFO : PROGRESS: at sentence #600000, processed 3000000 words, keeping 5632 word types\n",
      "2024-04-16 18:34:02,732 : INFO : PROGRESS: at sentence #610000, processed 3050000 words, keeping 5667 word types\n",
      "2024-04-16 18:34:02,743 : INFO : PROGRESS: at sentence #620000, processed 3100000 words, keeping 5714 word types\n",
      "2024-04-16 18:34:02,763 : INFO : PROGRESS: at sentence #630000, processed 3150000 words, keeping 5741 word types\n",
      "2024-04-16 18:34:02,777 : INFO : PROGRESS: at sentence #640000, processed 3200000 words, keeping 5775 word types\n",
      "2024-04-16 18:34:02,786 : INFO : PROGRESS: at sentence #650000, processed 3250000 words, keeping 5801 word types\n",
      "2024-04-16 18:34:02,807 : INFO : PROGRESS: at sentence #660000, processed 3300000 words, keeping 5852 word types\n",
      "2024-04-16 18:34:02,818 : INFO : PROGRESS: at sentence #670000, processed 3350000 words, keeping 5897 word types\n",
      "2024-04-16 18:34:02,838 : INFO : PROGRESS: at sentence #680000, processed 3400000 words, keeping 5927 word types\n",
      "2024-04-16 18:34:02,852 : INFO : PROGRESS: at sentence #690000, processed 3450000 words, keeping 5955 word types\n",
      "2024-04-16 18:34:02,863 : INFO : PROGRESS: at sentence #700000, processed 3500000 words, keeping 5989 word types\n",
      "2024-04-16 18:34:02,883 : INFO : PROGRESS: at sentence #710000, processed 3550000 words, keeping 6004 word types\n",
      "2024-04-16 18:34:02,898 : INFO : PROGRESS: at sentence #720000, processed 3600000 words, keeping 6036 word types\n",
      "2024-04-16 18:34:02,912 : INFO : PROGRESS: at sentence #730000, processed 3650000 words, keeping 6062 word types\n",
      "2024-04-16 18:34:02,919 : INFO : PROGRESS: at sentence #740000, processed 3700000 words, keeping 6079 word types\n",
      "2024-04-16 18:34:02,932 : INFO : PROGRESS: at sentence #750000, processed 3750000 words, keeping 6095 word types\n",
      "2024-04-16 18:34:02,952 : INFO : PROGRESS: at sentence #760000, processed 3800000 words, keeping 6118 word types\n",
      "2024-04-16 18:34:02,965 : INFO : PROGRESS: at sentence #770000, processed 3850000 words, keeping 6142 word types\n",
      "2024-04-16 18:34:02,980 : INFO : PROGRESS: at sentence #780000, processed 3900000 words, keeping 6165 word types\n",
      "2024-04-16 18:34:02,995 : INFO : PROGRESS: at sentence #790000, processed 3950000 words, keeping 6200 word types\n",
      "2024-04-16 18:34:03,007 : INFO : PROGRESS: at sentence #800000, processed 4000000 words, keeping 6242 word types\n",
      "2024-04-16 18:34:03,018 : INFO : PROGRESS: at sentence #810000, processed 4050000 words, keeping 6269 word types\n",
      "2024-04-16 18:34:03,040 : INFO : PROGRESS: at sentence #820000, processed 4100000 words, keeping 6285 word types\n",
      "2024-04-16 18:34:03,055 : INFO : PROGRESS: at sentence #830000, processed 4150000 words, keeping 6306 word types\n",
      "2024-04-16 18:34:03,063 : INFO : PROGRESS: at sentence #840000, processed 4200000 words, keeping 6326 word types\n",
      "2024-04-16 18:34:03,086 : INFO : PROGRESS: at sentence #850000, processed 4250000 words, keeping 6347 word types\n",
      "2024-04-16 18:34:03,102 : INFO : PROGRESS: at sentence #860000, processed 4300000 words, keeping 6369 word types\n",
      "2024-04-16 18:34:03,117 : INFO : PROGRESS: at sentence #870000, processed 4350000 words, keeping 6389 word types\n",
      "2024-04-16 18:34:03,131 : INFO : PROGRESS: at sentence #880000, processed 4400000 words, keeping 6407 word types\n",
      "2024-04-16 18:34:03,141 : INFO : PROGRESS: at sentence #890000, processed 4450000 words, keeping 6420 word types\n",
      "2024-04-16 18:34:03,153 : INFO : PROGRESS: at sentence #900000, processed 4500000 words, keeping 6439 word types\n",
      "2024-04-16 18:34:03,165 : INFO : PROGRESS: at sentence #910000, processed 4550000 words, keeping 6453 word types\n",
      "2024-04-16 18:34:03,186 : INFO : PROGRESS: at sentence #920000, processed 4600000 words, keeping 6470 word types\n",
      "2024-04-16 18:34:03,198 : INFO : PROGRESS: at sentence #930000, processed 4650000 words, keeping 6481 word types\n",
      "2024-04-16 18:34:03,209 : INFO : PROGRESS: at sentence #940000, processed 4700000 words, keeping 6508 word types\n",
      "2024-04-16 18:34:03,227 : INFO : PROGRESS: at sentence #950000, processed 4750000 words, keeping 6521 word types\n",
      "2024-04-16 18:34:03,242 : INFO : PROGRESS: at sentence #960000, processed 4800000 words, keeping 6536 word types\n",
      "2024-04-16 18:34:03,252 : INFO : PROGRESS: at sentence #970000, processed 4850000 words, keeping 6549 word types\n",
      "2024-04-16 18:34:03,273 : INFO : PROGRESS: at sentence #980000, processed 4900000 words, keeping 6561 word types\n",
      "2024-04-16 18:34:03,286 : INFO : PROGRESS: at sentence #990000, processed 4950000 words, keeping 6576 word types\n",
      "2024-04-16 18:34:03,297 : INFO : PROGRESS: at sentence #1000000, processed 5000000 words, keeping 6588 word types\n",
      "2024-04-16 18:34:03,309 : INFO : PROGRESS: at sentence #1010000, processed 5050000 words, keeping 6606 word types\n",
      "2024-04-16 18:34:03,328 : INFO : PROGRESS: at sentence #1020000, processed 5100000 words, keeping 6621 word types\n",
      "2024-04-16 18:34:03,340 : INFO : PROGRESS: at sentence #1030000, processed 5150000 words, keeping 6636 word types\n",
      "2024-04-16 18:34:03,352 : INFO : PROGRESS: at sentence #1040000, processed 5200000 words, keeping 6650 word types\n",
      "2024-04-16 18:34:03,363 : INFO : PROGRESS: at sentence #1050000, processed 5250000 words, keeping 6656 word types\n",
      "2024-04-16 18:34:03,386 : INFO : PROGRESS: at sentence #1060000, processed 5300000 words, keeping 6673 word types\n",
      "2024-04-16 18:34:03,401 : INFO : PROGRESS: at sentence #1070000, processed 5350000 words, keeping 6686 word types\n",
      "2024-04-16 18:34:03,407 : INFO : PROGRESS: at sentence #1080000, processed 5400000 words, keeping 6690 word types\n",
      "2024-04-16 18:34:03,419 : INFO : PROGRESS: at sentence #1090000, processed 5450000 words, keeping 6702 word types\n",
      "2024-04-16 18:34:03,438 : INFO : PROGRESS: at sentence #1100000, processed 5500000 words, keeping 6711 word types\n",
      "2024-04-16 18:34:03,455 : INFO : PROGRESS: at sentence #1110000, processed 5550000 words, keeping 6722 word types\n",
      "2024-04-16 18:34:03,468 : INFO : PROGRESS: at sentence #1120000, processed 5600000 words, keeping 6725 word types\n",
      "2024-04-16 18:34:03,474 : INFO : PROGRESS: at sentence #1130000, processed 5650000 words, keeping 6740 word types\n",
      "2024-04-16 18:34:03,487 : INFO : PROGRESS: at sentence #1140000, processed 5700000 words, keeping 6746 word types\n",
      "2024-04-16 18:34:03,507 : INFO : PROGRESS: at sentence #1150000, processed 5750000 words, keeping 6754 word types\n",
      "2024-04-16 18:34:03,521 : INFO : PROGRESS: at sentence #1160000, processed 5800000 words, keeping 6760 word types\n",
      "2024-04-16 18:34:03,535 : INFO : PROGRESS: at sentence #1170000, processed 5850000 words, keeping 6767 word types\n",
      "2024-04-16 18:34:03,550 : INFO : PROGRESS: at sentence #1180000, processed 5900000 words, keeping 6769 word types\n",
      "2024-04-16 18:34:03,565 : INFO : PROGRESS: at sentence #1190000, processed 5950000 words, keeping 6773 word types\n",
      "2024-04-16 18:34:03,577 : INFO : PROGRESS: at sentence #1200000, processed 6000000 words, keeping 6780 word types\n",
      "2024-04-16 18:34:03,585 : INFO : PROGRESS: at sentence #1210000, processed 6050000 words, keeping 6794 word types\n",
      "2024-04-16 18:34:03,606 : INFO : PROGRESS: at sentence #1220000, processed 6100000 words, keeping 6799 word types\n",
      "2024-04-16 18:34:03,618 : INFO : PROGRESS: at sentence #1230000, processed 6150000 words, keeping 6807 word types\n",
      "2024-04-16 18:34:03,631 : INFO : PROGRESS: at sentence #1240000, processed 6200000 words, keeping 6811 word types\n",
      "2024-04-16 18:34:03,646 : INFO : PROGRESS: at sentence #1250000, processed 6250000 words, keeping 6815 word types\n",
      "2024-04-16 18:34:03,651 : INFO : PROGRESS: at sentence #1260000, processed 6300000 words, keeping 6821 word types\n",
      "2024-04-16 18:34:03,674 : INFO : PROGRESS: at sentence #1270000, processed 6350000 words, keeping 6824 word types\n",
      "2024-04-16 18:34:03,689 : INFO : PROGRESS: at sentence #1280000, processed 6400000 words, keeping 6830 word types\n",
      "2024-04-16 18:34:03,701 : INFO : PROGRESS: at sentence #1290000, processed 6450000 words, keeping 6835 word types\n",
      "2024-04-16 18:34:03,708 : INFO : PROGRESS: at sentence #1300000, processed 6500000 words, keeping 6835 word types\n",
      "2024-04-16 18:34:03,731 : INFO : PROGRESS: at sentence #1310000, processed 6550000 words, keeping 6841 word types\n",
      "2024-04-16 18:34:03,745 : INFO : collected 6845 word types from a corpus of 6599935 raw words and 1319987 sentences\n",
      "2024-04-16 18:34:03,745 : INFO : Creating a fresh vocabulary\n",
      "2024-04-16 18:34:03,752 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 retains 6215 unique words (90.80% of original 6845, drops 630)', 'datetime': '2024-04-16T18:34:03.752095', 'gensim': '4.3.2', 'python': '3.8.19 | packaged by conda-forge | (default, Mar 20 2024, 12:38:07) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2024-04-16 18:34:03,752 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 6596946 word corpus (99.95% of original 6599935, drops 2989)', 'datetime': '2024-04-16T18:34:03.752095', 'gensim': '4.3.2', 'python': '3.8.19 | packaged by conda-forge | (default, Mar 20 2024, 12:38:07) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2024-04-16 18:34:03,775 : INFO : deleting the raw counts dictionary of 6845 items\n",
      "2024-04-16 18:34:03,775 : INFO : sample=0.001 downsamples 46 most-common words\n",
      "2024-04-16 18:34:03,777 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 3915120.334561057 word corpus (59.3%% of prior 6596946)', 'datetime': '2024-04-16T18:34:03.777008', 'gensim': '4.3.2', 'python': '3.8.19 | packaged by conda-forge | (default, Mar 20 2024, 12:38:07) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2024-04-16 18:34:03,795 : INFO : estimated required memory for 6215 words and 300 dimensions: 18023500 bytes\n",
      "2024-04-16 18:34:03,795 : INFO : resetting layer weights\n",
      "2024-04-16 18:34:03,807 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-04-16T18:34:03.807628', 'gensim': '4.3.2', 'python': '3.8.19 | packaged by conda-forge | (default, Mar 20 2024, 12:38:07) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2024-04-16 18:34:03,808 : INFO : Word2Vec lifecycle event {'msg': 'training model with 10 workers on 6215 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=8 window=5 shrink_windows=True', 'datetime': '2024-04-16T18:34:03.808625', 'gensim': '4.3.2', 'python': '3.8.19 | packaged by conda-forge | (default, Mar 20 2024, 12:38:07) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2024-04-16 18:34:04,816 : INFO : EPOCH 0 - PROGRESS: at 39.55% examples, 1531057 words/s, in_qsize 0, out_qsize 0\n",
      "2024-04-16 18:34:05,816 : INFO : EPOCH 0 - PROGRESS: at 77.73% examples, 1518533 words/s, in_qsize 5, out_qsize 0\n",
      "2024-04-16 18:34:06,383 : INFO : EPOCH 0: training on 6599935 raw words (3915180 effective words) took 2.6s, 1515783 effective words/s\n",
      "2024-04-16 18:34:07,405 : INFO : EPOCH 1 - PROGRESS: at 34.39% examples, 1331601 words/s, in_qsize 20, out_qsize 0\n",
      "2024-04-16 18:34:08,406 : INFO : EPOCH 1 - PROGRESS: at 69.70% examples, 1359902 words/s, in_qsize 16, out_qsize 0\n",
      "2024-04-16 18:34:09,233 : INFO : EPOCH 1: training on 6599935 raw words (3914940 effective words) took 2.8s, 1380518 effective words/s\n",
      "2024-04-16 18:34:10,228 : INFO : EPOCH 2 - PROGRESS: at 31.82% examples, 1240224 words/s, in_qsize 20, out_qsize 0\n",
      "2024-04-16 18:34:11,231 : INFO : EPOCH 2 - PROGRESS: at 65.00% examples, 1272483 words/s, in_qsize 18, out_qsize 0\n",
      "2024-04-16 18:34:12,183 : INFO : EPOCH 2: training on 6599935 raw words (3914062 effective words) took 3.0s, 1323739 effective words/s\n",
      "2024-04-16 18:34:13,195 : INFO : EPOCH 3 - PROGRESS: at 33.03% examples, 1289909 words/s, in_qsize 19, out_qsize 0\n",
      "2024-04-16 18:34:14,195 : INFO : EPOCH 3 - PROGRESS: at 67.27% examples, 1314762 words/s, in_qsize 17, out_qsize 2\n",
      "2024-04-16 18:34:15,117 : INFO : EPOCH 3: training on 6599935 raw words (3915957 effective words) took 2.9s, 1339331 effective words/s\n",
      "2024-04-16 18:34:16,124 : INFO : EPOCH 4 - PROGRESS: at 33.18% examples, 1291930 words/s, in_qsize 0, out_qsize 1\n",
      "2024-04-16 18:34:17,144 : INFO : EPOCH 4 - PROGRESS: at 65.76% examples, 1274540 words/s, in_qsize 18, out_qsize 1\n",
      "2024-04-16 18:34:18,077 : INFO : EPOCH 4: training on 6599935 raw words (3913817 effective words) took 3.0s, 1324953 effective words/s\n",
      "2024-04-16 18:34:18,077 : INFO : Word2Vec lifecycle event {'msg': 'training on 32999675 raw words (19573956 effective words) took 14.3s, 1371751 effective words/s', 'datetime': '2024-04-16T18:34:18.077935', 'gensim': '4.3.2', 'python': '3.8.19 | packaged by conda-forge | (default, Mar 20 2024, 12:38:07) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2024-04-16 18:34:18,078 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'w2vmodel_ng5_2000_2010_full', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2024-04-16T18:34:18.078920', 'gensim': '4.3.2', 'python': '3.8.19 | packaged by conda-forge | (default, Mar 20 2024, 12:38:07) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'saving'}\n",
      "2024-04-16 18:34:18,079 : INFO : not storing attribute cum_table\n",
      "2024-04-16 18:34:18,084 : INFO : saved w2vmodel_ng5_2000_2010_full\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import gensim\n",
    "import logging\n",
    "import numpy\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname, start_year, end_year, limit=None):\n",
    "        self.dirname = dirname\n",
    "        self.start_year = start_year\n",
    "        self.end_year = end_year\n",
    "        self.limit = limit\n",
    "\n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            with gensim.utils.open(os.path.join(self.dirname, fname)) as fin:\n",
    "                for line in itertools.islice(fin, self.limit):\n",
    "                    line = gensim.utils.to_unicode(line).split(\"\\t\")\n",
    "                    if len(line) < 3:\n",
    "                        continue\n",
    "                    ngram = line[0]\n",
    "                    try:\n",
    "                        year = int(line[1])\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                    match_count = int(line[2])\n",
    "                    if year < self.start_year or year > self.end_year:\n",
    "                        continue\n",
    "                    processed_ngram = [word.split(\"_\")[0] for word in ngram.lower().split()]\n",
    "                    for x in range(match_count):\n",
    "                        yield processed_ngram\n",
    "\n",
    "# Define year_1 and year_2\n",
    "year_1 = 2000\n",
    "year_2 = 2010\n",
    "\n",
    "# Create sentences iterator\n",
    "sentences = MySentences(\"C:/Users/malfa/Downloads/ngrams/ngrams2\", year_1, year_2)\n",
    "\n",
    "# Build the vocabulary\n",
    "model = gensim.models.word2vec.Word2Vec(vector_size=300, window=5, min_count=10, workers=10, hs=0, negative=8)\n",
    "model.build_vocab(sentences)\n",
    "\n",
    "# Train word2vec model\n",
    "model.train(sentences, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "# Save the model\n",
    "model.save('w2vmodel_ng5_'+str(year_1)+'_'+str(year_2)+'_full')\n",
    "\n",
    "# Save the vectors\n",
    "numpy.savetxt('syn0_ngf_'+str(year_1)+'_'+str(year_2)+'_full.txt', model.wv.vectors, delimiter=\" \")\n",
    "\n",
    "# Save the vocabulary list\n",
    "vocab_list = model.wv.index_to_key\n",
    "for i in range(0, len(vocab_list)):\n",
    "    if vocab_list[i] == '':\n",
    "        vocab_list[i] = \"thisisanemptytoken\"+str(i)\n",
    "\n",
    "with open('vocab_list_ngf_'+str(year_1)+'_'+str(year_2)+'_full.txt', 'wb') as outfile:\n",
    "    for i in range(0, len(vocab_list)):\n",
    "        outfile.write(vocab_list[i].encode('utf8')+\"\\n\".encode('ascii'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "# Placeholder for the data directory and years\n",
    "dirname = \"/ngrams/googlebooks-eng-all-5gram-20120701-0/googlebooks-eng-all-5gram-20120701-0/\"\n",
    "start_year = 2000\n",
    "end_year = 2012\n",
    "\n",
    "# Function to read and preprocess n-grams\n",
    "def read_ngrams(dirname, start_year, end_year, limit=None):\n",
    "    vocab = Counter()\n",
    "    data = []\n",
    "    for fname in os.listdir(dirname):\n",
    "        with open(os.path.join(dirname, fname), 'r') as fin:\n",
    "            for line in itertools.islice(fin, limit):\n",
    "                parts = line.strip().split(\"\\t\")\n",
    "                if len(parts) < 3:\n",
    "                    continue\n",
    "                ngram, year, match_count = parts[0], int(parts[1]), int(parts[2])\n",
    "                if start_year <= year <= end_year:\n",
    "                    words = [word.split(\"_\")[0].lower() for word in ngram.split()]\n",
    "                    vocab.update(words)\n",
    "                    data.append(words)\n",
    "    return data, vocab\n",
    "\n",
    "data, vocab = read_ngrams(dirname, start_year, end_year)\n",
    "\n",
    "# Function to build a vocabulary index\n",
    "def build_vocab_index(vocab):\n",
    "    vocab_index = {word: i for i, (word, _) in enumerate(vocab.most_common(), 1)}\n",
    "    return vocab_index\n",
    "\n",
    "vocab_index = build_vocab_index(vocab)\n",
    "\n",
    "# Function to convert words to indices\n",
    "def words_to_indices(data, vocab_index):\n",
    "    indexed_data = []\n",
    "    for sentence in data:\n",
    "        indexed_sentence = [vocab_index[word] for word in sentence if word in vocab_index]\n",
    "        indexed_data.append(indexed_sentence)\n",
    "    return indexed_data\n",
    "\n",
    "indexed_data = words_to_indices(data, vocab_index)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leosan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
